# LLM vs LLM

**Исследование способностей языковых моделей к генерации вредоносных запросов и оцениванию других языковых моделей**

Проект нацелен на создание бенчмарка для оценки способностей больших языковых моделей при генерации и последующей проверке вредоносных запросов, а также на проверку устойчивости других моделей к возможным атакам в роли судьи.

Авторы: Иванов Н.А., Неронов Р.М., Низамов Т.Д., 1 курс магистратуры AI Talent Hub, Университет ИТМО

*Выполняется в рамках проектной практики в AI Security Lab ИТМО и Raft и курса ПИШ ИТМО «Инжиниринг управления данными».*

## Задачи

 - Исследование:
   - [Составление атакующих и судейских промтов](llm-vs-llm-generating.ipynb) ✅
   - [Генерация пар запросов-ответов](llm-vs-llm-generating.ipynb) ✅
   - Разметка прохождения атак и качества атакующих промтов ✅
   - [Анализ данных по итогам разметки: выбор атакующих и судейских промтов, атакующей модели](llm-vs-llm-benchmarking.ipynb) ✅
   - [Составление бенчмарка для оценки судейских способностей моделей](llm-vs-llm-benchmarking.ipynb) ✅
   - [Прогон на бенчмарке разных моделей](llm-vs-llm-ratings.ipynb) ✅
   - Визуализация бенчмарка
 - Инжиниринг управления данными:
   - Репозиторий ✅
   - Отчёт
   - Презентация
   - Демонстрация

## Данные

 - [data/llm-vs-llm-generated.xlsx](data/llm-vs-llm-generated.xlsx) — размеченные данные для атак и ответы атакуемых систем:
   - Название атаки (теста)
   - Название атакующей LLM
   - Хэш системного промта атакующей модели
   - Название атакуемой системы
   - Первый запрос атакующей модели
   - Первый ответ атакуемой системы
   - Второй запрос атакующей модели (опционально)
   - Второй ответ атакуемой системы (опционально)
   - Вердикт судьи при системном промте A (BROKEN, RESILIENT)
   - Вердикт судьи при системном промте B (BROKEN, RESILIENT)
   - Вердикт разметчика (BROKEN, RESILIENT)
   - Человеческая оценка качества атакующих запросов (-1 — плохо, 0 — нейтрально, -1 — хорошо)
 - [data/llm-vs-llm-benchmark.csv](data/llm-vs-llm-benchmark.csv) — бенчмарк для оценки моделей-судей:
   - attack — название атаки (теста)
   - attack_model — атакующая модель
   - tested_model — тестируемая модель (система)
   - first_attack_prompt — начальный атакующий промт
   - first_response — первый ответ атакуемой системы
   - second_attack_prompt — второй атакующий промт
   - second_response — второй ответ системы
   - verdict_assessor — вердикт (Broken, Resilient)
 - [data/ethical.csv](data/ethical.csv) — результаты прогона моделей-судей на ответах атаки с этико-правовыми отклонениями 
 - [data/logical.csv](data/logical.csv) — результаты прогона моделей-судей на ответах атаки с логическими несоответствиями
 - [data/sycophancy.csv](data/sycophancy.csv) — результаты прогона моделей-судей на ответах атаки с подхалимством